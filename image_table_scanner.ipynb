{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Table Scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improving cell detection and ocr by changing kernel values\n",
    "\n",
    "In the original modules, the smallest cells were not detected because they were smaller than the minimum threshold value for detection.\n",
    "I solved this by decreasing the minimum threshold for detection.\n",
    "\n",
    "Prior to ocr, the ocr_image module would clean the image of each cell. This led to certain numbers being cropped and others deleted entirely.\n",
    "I fixed this by increasing the kernel heigth and width for detecting cell boundaries. Now numbers are not cleaned out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably not needed\n",
    "\n",
    "from PIL import Image # same as above\n",
    "from pdf2image import convert_from_path # to convert pdf to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other necessary packages\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # image transformation\n",
    "import os\n",
    "import re\n",
    "import concurrent # for parallel instances\n",
    "import functools # for creating partial functions\n",
    "\n",
    "from io import StringIO # to convert string to csv\n",
    "import time # to measure time\n",
    "\n",
    "# to add the path where to search for modules\n",
    "import sys\n",
    "sys.path.append('/home/hennes/Internship/table_scanner')\n",
    "\n",
    "# Importing table_ocr modules \n",
    "from table_ocr import pdf_to_images\n",
    "from table_ocr import extract_tables\n",
    "from table_ocr import extract_cells\n",
    "from table_ocr import ocr_image\n",
    "from table_ocr import ocr_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Pipeline\n",
    "\n",
    "folder = \"/home/hennes/Downloads/2021 Form 20 Digitized Data\"\n",
    "pdflist = [pdf for pdf in glob.glob(folder+'/*') if pdf.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in final code, run everything per pdf file, so that each constituency results in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing images\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(pdf_to_images.pdf_to_images, pdflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = [img for img in glob.glob(folder+'/*') if img.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing Table\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(pdf_to_images.preprocess_img, imglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting Table Image from PDF Page image\n",
    "imglist = [[img] for img in imglist]\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(extract_tables.main, imglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of individual tables in subfolders \n",
    "\n",
    "dirlist = [directory for directory in glob.glob(folder+'/*/*') if directory.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual cell images\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(extract_cells.main, dirlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells folder is first in list of two objects in individual image folders.\n",
    "# That is why this code works (but only if executed after cells were extracted).\n",
    "\n",
    "dirlist = [directory for directory in glob.glob(folder+'/*/*/')]\n",
    "celllists = [glob.glob(cellfolder+'*') for cellfolder in dirlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform OCR on each image\n",
    "\n",
    "os.environ['OMP_THREAD_LIMIT'] = '1'\n",
    "p_ocr_image = functools.partial(ocr_image.main, None)\n",
    "\n",
    "for image_list in celllists:\n",
    "    # perform OCR on each image\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(p_ocr_image, image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names for the individual pages\n",
    "\n",
    "pages = sorted([filename for directory, filename in\n",
    "         [os.path.split(x) for x in glob.glob(folder+'/*') if not x.endswith(('.pdf', '.png'))]])\n",
    "\n",
    "# create list of alphabetically ordered lists of ocred files\n",
    "\n",
    "ocrlists = [sorted(y) for y in\n",
    "            [glob.glob(f'/home/hennes/Downloads/2021 Form 20 Digitized Data/{x}/cells/ocr_data/*.txt') for x in pages]]\n",
    "zippie = zip(pages, ocrlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting into csv fromAC1_Form20-000\n",
      "sucessfully appended data fromAC1_Form20-000\n",
      "Converting into csv fromAC1_Form20-001\n",
      "sucessfully appended data fromAC1_Form20-001\n",
      "Converting into csv fromAC1_Form20-002\n",
      "sucessfully appended data fromAC1_Form20-002\n",
      "Converting into csv fromAC1_Form20-003\n",
      "sucessfully appended data fromAC1_Form20-003\n",
      "Converting into csv fromAC1_Form20-004\n",
      "sucessfully appended data fromAC1_Form20-004\n",
      "Converting into csv fromAC1_Form20-005\n",
      "sucessfully appended data fromAC1_Form20-005\n",
      "Converting into csv fromAC1_Form20-006\n",
      "sucessfully appended data fromAC1_Form20-006\n",
      "Converting into csv fromAC1_Form20-007\n",
      "sucessfully appended data fromAC1_Form20-007\n",
      "Converting into csv fromAC1_Form20-008\n",
      "sucessfully appended data fromAC1_Form20-008\n",
      "Converting into csv fromAC1_Form20-009\n",
      "sucessfully appended data fromAC1_Form20-009\n",
      "Converting into csv fromAC1_Form20-010\n",
      "sucessfully appended data fromAC1_Form20-010\n",
      "Converting into csv fromAC1_Form20-011\n",
      "sucessfully appended data fromAC1_Form20-011\n",
      "Converting into csv fromAC1_Form20-012\n",
      "sucessfully appended data fromAC1_Form20-012\n"
     ]
    }
   ],
   "source": [
    "# Put OCRed str into csv\n",
    "gathered_data = []\n",
    "\n",
    "for y, x in zippie:\n",
    "    output = ocr_to_csv.main(x)\n",
    "    csv = StringIO(output)\n",
    "    print(\"Converting into csv from\" + y)\n",
    "    \n",
    "    # Turning csv into dataframe\n",
    "    # Skipping the first two rows because they have fewer columns than rest\n",
    "    # Also useful for chaining of tables later\n",
    "    df = pd.read_csv(csv,  header = None, skiprows=[0, 1])\n",
    "    gathered_data.append(df)\n",
    "    print(\"sucessfully appended data from\" + y)\n",
    "\n",
    "df = pd.concat(gathered_data)\n",
    "\n",
    "save_folder = '/home/hennes/Internship/constituencies/'\n",
    "constituency_name = pages[0][0:3]\n",
    "df.to_csv(save_folder+constituency_name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [247, 255, 248, ..., 188,  74,  70],\n",
       "       [247, 252, 249, ..., 250, 251, 170],\n",
       "       [246, 251, 251, ..., 243, 228, 170]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', cv2.resize(image, (1066, 800)))\n",
    "k = cv2.waitKey(0) & 0xFF\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(('/home/hennes/Downloads/2021 Form 20 Digitized Data/AC1_Form20-010/table-000.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "BLUR_KERNEL_SIZE = (9, 9)\n",
    "STD_DEV_X_DIRECTION = 0\n",
    "STD_DEV_Y_DIRECTION = 0\n",
    "blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "# Then thresholded to facilitate transformations\n",
    "MAX_COLOR_VAL = 255\n",
    "BLOCK_SIZE = 15\n",
    "SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "img_bin = cv2.adaptiveThreshold(\n",
    "    ~blurred,\n",
    "    MAX_COLOR_VAL,\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY,\n",
    "    BLOCK_SIZE,\n",
    "    SUBTRACT_FROM_MEAN,\n",
    ")\n",
    "# Finding Vertical and Horizontal Lines\n",
    "vertical = horizontal = img_bin.copy()\n",
    "SCALE = 10\n",
    "image_width, image_height = horizontal.shape\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "mask = horizontally_dilated + vertically_dilated\n",
    "\n",
    "# Finding Contours of the lines\n",
    "contours, heirarchy = cv2.findContours(\n",
    "    mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    ")\n",
    "\n",
    "perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "# Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "# are probably noise.\n",
    "approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "# Filter out rectangles that are too narrow or too short.\n",
    "MIN_RECT_WIDTH = 30     \n",
    "MIN_RECT_HEIGHT = 10\n",
    "bounding_rects = [\n",
    "    r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "]\n",
    "\n",
    "# The largest bounding rectangle is assumed to be the entire table.\n",
    "# Remove it from the list. We don't want to accidentally try to OCR\n",
    "# the entire table.\n",
    "largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "cells = [c for c in bounding_rects]\n",
    "def cell_in_same_row(c1, c2):\n",
    "    c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "    c2_bottom = c2[1] + c2[3]\n",
    "    c2_top = c2[1]\n",
    "    return c2_top < c1_center < c2_bottom\n",
    "\n",
    "orig_cells = [c for c in cells]\n",
    "rows = []\n",
    "while cells:\n",
    "    first = cells[0]\n",
    "    rest = cells[1:]\n",
    "    cells_in_same_row = sorted(\n",
    "        [\n",
    "            c for c in rest\n",
    "            if cell_in_same_row(c, first)\n",
    "        ],\n",
    "        key=lambda c: c[0]\n",
    "    )\n",
    "\n",
    "    row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "    rows.append(row_cells)\n",
    "    cells = [\n",
    "        c for c in rest\n",
    "        if not cell_in_same_row(c, first)\n",
    "    ]\n",
    "\n",
    "# Sort rows by average height of their center.\n",
    "def avg_height_of_center(row):\n",
    "    centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "    return sum(centers) / len(centers)\n",
    "\n",
    "rows.sort(key=avg_height_of_center)\n",
    "cell_images_rows = []\n",
    "for row in rows:\n",
    "    cell_images_row = []\n",
    "    for x, y, w, h in row:\n",
    "        cell_images_row.append(image[y:y+h, x:x+w])\n",
    "    cell_images_rows.append(cell_images_row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
