{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "1. Import packages and define folders\n",
    "2. Choose which files to use as input\n",
    "3. Instantiate functions\n",
    "4. Run Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other necessary packages\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # image transformation\n",
    "import os\n",
    "import re\n",
    "import concurrent # for parallel instances\n",
    "import functools # for creating partial functions\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from io import StringIO # to convert string to csv\n",
    "import time # to measure time\n",
    "\n",
    "# to add the path where to search for modules\n",
    "import sys\n",
    "sys.path.append('/home/hennes/Internship/table_scanner')\n",
    "\n",
    "# Importing table_ocr modules \n",
    "from table_ocr import pdf_to_images\n",
    "from table_ocr import extract_tables\n",
    "from table_ocr import extract_cells\n",
    "from table_ocr import ocr_image\n",
    "from table_ocr import ocr_to_csv\n",
    "\n",
    "## setting folders and pdfs\n",
    "folder = \"/home/hennes/Internship/pdfs/\" # should be folder containing pdfs of election\n",
    "save_folder = '/home/hennes/Internship/constituencies/' # folder into which csvs should be saved\n",
    "saved = [os.path.splitext(csv)[0] for csv in next(os.walk(save_folder))[2]]\n",
    "old = '/home/hennes/Internship/old_files/' # folder into which old files are moved\n",
    "old_files = [folder for folder in next(os.walk(old))[1]]\n",
    "allpdf = [pdf for pdf in glob.glob(folder+'*') if pdf.endswith(\".pdf\")] # list with all pdfs from folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing files (Choose one of the following options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input = pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all pdfs that do not have a corresponding file in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude pdfs for which there is already a csv in save folder\n",
    "pdflist = sorted([pdf for pdf in allpdf if pdf.split('/')[-1].split('_')[0].split('.')[0] not in\n",
    "           [file.split('/')[-1].split('.')[0] for file in glob.glob(save_folder+'*')]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdfs as per excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/hennes/Downloads/Book.xlsx')\n",
    "\n",
    "# get relevant pdf numbers\n",
    "\n",
    "worklist = df[df['Comments'] == 'redo']['Constituency number'].tolist()\n",
    "\n",
    "# give appropriate filename endings to items\n",
    "\n",
    "for idx, item in enumerate(worklist):\n",
    "    if len(str(item)) == 1:\n",
    "        worklist[idx] = f'AC00{item}.pdf'\n",
    "    if len(str(item)) == 2:\n",
    "        worklist[idx] = f'AC0{item}.pdf'\n",
    "    if len(str(item)) == 3:\n",
    "        worklist[idx] = f'AC{item}.pdf'\n",
    "        \n",
    "worklist = tuple(worklist)\n",
    "pdflist = [pdf for pdf in allpdf if pdf.endswith(worklist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all ACs that do not have a corresponding file in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates list of lists with each list containing the folders of one AC constituency\n",
    "filelist = []\n",
    "for e in set(sorted([folder.split('-')[1] for folder in next(os.walk(old))[1] if folder.split('-')[1] not in saved])):\n",
    "    filelist.append(sorted([folder for folder in old_files if folder.split('-')[1] in e]))\n",
    "filelist = sorted(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ACs as per excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for e in set(sorted([folder.split('-')[1] for folder in next(os.walk(old))[1]])):\n",
    "    filelist.append(sorted([folder for folder in old_files if folder.split('-')[1] in e]))\n",
    "filelist = sorted(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b4a0aff16dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mworklist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworklist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworklist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b4a0aff16dd2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mworklist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworklist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworklist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# first get list of lists with all files\n",
    "\n",
    "filelist = []\n",
    "for e in set(sorted([folder.split('-')[1] for folder in next(os.walk(old))[1]])):\n",
    "    filelist.append(sorted([folder for folder in old_files if folder.split('-')[1] in e]))\n",
    "filelist = sorted(filelist)\n",
    "\n",
    "\n",
    "# then filter as per excel\n",
    "df = pd.read_excel('/home/hennes/Downloads/Book.xlsx')\n",
    "\n",
    "# get relevant pdf numbers\n",
    "\n",
    "worklist = df[df['Comments'] == 'redo OCR']['Constituency number'].tolist()\n",
    "\n",
    "# give appropriate filename endings to items\n",
    "\n",
    "for idx, item in enumerate(worklist):\n",
    "    if len(str(item)) == 1:\n",
    "        worklist[idx] = f'AC00{item}'\n",
    "    if len(str(item)) == 2:\n",
    "        worklist[idx] = f'AC0{item}'\n",
    "    if len(str(item)) == 3:\n",
    "        worklist[idx] = f'AC{item}'\n",
    "        \n",
    "worklist = tuple(worklist)\n",
    "\n",
    "filelist = [l for l in filelist if l[0].split('-')[1] in worklist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning eventual files still in pdf folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files(folder, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For when input is folders from old folder (tables already extracted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "WORKING ON 12\n",
      " \n",
      "extracted cells of 12\n",
      "completed ocr of 12\n",
      "working on AC017-02\n",
      "working on AC017-03\n",
      "working on AC017-07\n",
      "working on AC017-08\n",
      "working on AC017-09\n",
      "working on AC017-10\n",
      "working on AC017-11\n",
      "working on AC017-12\n",
      "working on AC017-13\n",
      "working on AC017-14\n",
      "working on AC017-15\n",
      "Saved 02 to folder.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0d1fcf6c2054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/{l[0].split(\"-\")[1]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' \\nWORKING ON {pdf.split(\"/\")[-1]}\\n '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocr_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for l in filelist:\n",
    "    [shutil.copytree(old+x, folder+x) for x in l]\n",
    "    pdf = f'/{l[0].split(\"-\")[1]}'\n",
    "    print(f' \\nWORKING ON {pdf.split(\"/\")[-1]}\\n ')\n",
    "    stop = ocr_pipeline(pdf, from_cell=True, dilate=None)\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For when input is image files from old folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'worklist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cd6c91b9f212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdflist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworklist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'worklist' is not defined"
     ]
    }
   ],
   "source": [
    "pdflist = [e.split('.')[0] for e in worklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "WORKING ON /home/hennes/Internship/pdfs/AC177.pdf\n",
      " \n",
      "extracted tables of AC177.pdf.pdf\n",
      "extracted cells of AC177.pdf.pdf\n",
      "completed ocr of AC177.pdf.pdf\n",
      "working on AC177-01\n",
      "working on AC177-02\n",
      "working on AC177-03\n",
      "working on AC177-04\n",
      "working on AC177-05\n",
      "working on AC177-06\n",
      "working on AC177-07\n",
      "working on AC177-08\n",
      "Error tokenizing data. C error: Expected 14 fields in line 9, saw 15\n",
      "\n",
      "will try again ignoring one more line.\n",
      "working on AC177-01\n",
      "working on AC177-02\n",
      "working on AC177-03\n",
      "working on AC177-04\n",
      "working on AC177-05\n",
      "working on AC177-06\n",
      "working on AC177-07\n",
      "working on AC177-08\n",
      "Saved AC177 to folder.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-33ec0b8382fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdflist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimglist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimglist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{folder}/{x}.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' \\nWORKING ON {x}\\n '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-33ec0b8382fa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdflist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimglist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimglist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{folder}/{x}.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' \\nWORKING ON {x}\\n '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/posixpath.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n\u001b[1;32m    102\u001b[0m     everything after the final slash.  Either part may be empty.\"\"\"\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "for x in pdflist:\n",
    "    imglist = [img for img in next(os.walk(old))[2] if img.startswith(os.path.split(x)[1].split('.')[0])]\n",
    "    [shutil.copy(old+x, folder) for x in imglist]\n",
    "    pdf = f'{folder}/{x}.pdf'\n",
    "    print(f' \\nWORKING ON {x}\\n ')\n",
    "    stop = ocr_pipeline(pdf, preprocess = False, image_conversion = False)\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For when input files are pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no options\n",
    "pdflist = ['/home/hennes/Internship/pdfs/AC229.pdf', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "WORKING ON /home/hennes/Internship/pdfs/AC229.pdf\n",
      " \n",
      "created images of AC229.pdf\n",
      "preprocessed images of AC229.pdf\n",
      "Extraction error: /home/hennes/Internship/pdfs/AC229-15.png.\n",
      "extracted tables of AC229.pdf\n",
      "extracted cells of AC229.pdf\n",
      "completed ocr of AC229.pdf\n",
      "working on AC229-01\n",
      "working on AC229-02\n",
      "working on AC229-03\n",
      "working on AC229-04\n",
      "working on AC229-05\n",
      "working on AC229-06\n",
      "working on AC229-07\n",
      "working on AC229-08\n",
      "working on AC229-09\n",
      "working on AC229-10\n",
      "working on AC229-11\n",
      "working on AC229-12\n",
      "working on AC229-13\n",
      "working on AC229-14\n",
      "Saved AC229 to folder.\n",
      " \n",
      "WORKING ON None\n",
      " \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0ce5e20125cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdflist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' \\nWORKING ON {x}\\n '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocr_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e6a50f25d7d7>\u001b[0m in \u001b[0;36mocr_pipeline\u001b[0;34m(pdf, thresh, no_noise, preprocess, dilate, image_conversion, AC, from_cell)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_conversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# extract pages from pdf and save as images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mpdf_to_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_to_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"created images of {pdf.split('/')[-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Internship/table_scanner/table_ocr/pdf_to_images/__init__.py\u001b[0m in \u001b[0;36mpdf_to_images\u001b[0;34m(pdf_filepath)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mimages\u001b[0m \u001b[0msorted\u001b[0m \u001b[0mlexicographically\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mimage_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfimages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/posixpath.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n\u001b[1;32m    102\u001b[0m     everything after the final slash.  Either part may be empty.\"\"\"\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "for x in pdflist:\n",
    "    print(f' \\nWORKING ON {x}\\n ')\n",
    "    stop = ocr_pipeline(x, thresh = True, no_noise = True)\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_files(folder, old):\n",
    "    # if folder already exist, delete it. Then move folders to old directory.\n",
    "    [shutil.rmtree(old+'/'+e)\n",
    "     for e in next(os.walk(folder))[1] if Path(old+'/'+e).is_dir()]\n",
    "\n",
    "    [shutil.move(folder+''+e, old)\n",
    "     for e in next(os.walk(folder))[1] if not e.endswith('.pdf')]\n",
    "\n",
    "    # if files already exist, delete them. Then move files to old directory.\n",
    "    [os.remove(old+'/'+e)\n",
    "     for e in next(os.walk(folder))[2] if not e.endswith('.pdf') and Path(old+'/'+e).is_file()]\n",
    "\n",
    "    [shutil.move(e, old)\n",
    "     for e in glob.glob(folder+'*') if not e.endswith('.pdf')]\n",
    "\n",
    "def ocr_pipeline(pdf, thresh=None, no_noise=None, preprocess=True, dilate=True, image_conversion=True,\n",
    "                 AC = False, from_cell = False):\n",
    "    '''Function which binds together the functions necessary to turn one pdf of several pages of tables\n",
    "    into a csv file which will be stored under the same name in the specified folder.\n",
    "    The options are:\n",
    "    \n",
    "    image_conversion - whether images should be converted from pdf. If value is None, then converted \n",
    "                       images should already be supplied in the folder.\n",
    "    \n",
    "    thresh           - whether otsu thresholding should be applied to cell images before performing ocr.\n",
    "                       Useful if the images contain a lot of grey, in which case not thresholding likely\n",
    "                       results in many artifacts wrongly identified as numbers.\n",
    "    \n",
    "    no_noise         - whether noise reduction techniques should be used before ocr. It should be avoided in\n",
    "                       images with very thin/small font. Helpful in case of cropping error (in that case, put TRUE).\n",
    "                \n",
    "    preprocess       - whether preprocessing should be used before table extraction. Useful to avoid if\n",
    "                       preprocessing results in wrongly rotated images. Can only be used if function is\n",
    "                       used on already extracted images.\n",
    "                 \n",
    "    dilate           - whether image should be dilated before cell extraction. Useful for thin/frail cell\n",
    "                       lines, but results in numbers becoming so thick that they are recognised as cell \n",
    "                       walls themselves in images with tightly written fonts.\n",
    "    \n",
    "    AC               - whether the folders created with table_extraction should be named after the AC con-\n",
    "                       stituency, which is extracted from the images using OCR. This is necessary for the \n",
    "                       national elections, which use a different constituency system. Pipeline stops after\n",
    "                       the renaming.\n",
    "                       \n",
    "    from_cell        - \"True\" = workflow starts from cell extraction. Only works if input is folders from \n",
    "                       old folder.\n",
    "                       \"False\" = workflow starts from image conversion. Input are pdf files.'''\n",
    "    \n",
    "    stop = None\n",
    "    \n",
    "    if from_cell == False:\n",
    "        if image_conversion == True:\n",
    "            # extract pages from pdf and save as images \n",
    "            pdf_to_images.pdf_to_images(pdf)\n",
    "            print(f\"created images of {pdf.split('/')[-1]}\")\n",
    "\n",
    "        # define list of images thus created\n",
    "        imglist = [img for img in glob.glob(folder+'*') if img.endswith('.png')]\n",
    "\n",
    "        if preprocess == True:\n",
    "            # rotate and correct images for skew\n",
    "            with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "                executor.map(pdf_to_images.preprocess_img, imglist)\n",
    "            print(f\"preprocessed images of {pdf.split('/')[-1]}\")\n",
    "\n",
    "        # crop images to table and save in new folder\n",
    "        if AC == False:\n",
    "            # define imglist as list of lists because next function needs list as argument\n",
    "            imglist = [[img] for img in imglist]\n",
    "\n",
    "            # Create partial function for table extraction in which AC is negative\n",
    "            p_extract_tables = functools.partial(extract_tables.main, AC)\n",
    "\n",
    "            with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "                executor.map(p_extract_tables, imglist)\n",
    "            print(f\"extracted tables of {pdf.split('/')[-1]}\")\n",
    "\n",
    "        elif AC == True:\n",
    "            # sort imglist\n",
    "            imglist = sorted(imglist)\n",
    "\n",
    "            extract_tables.main(AC, imglist)\n",
    "            print(f\"extracted tables of {pdf.split('/')[-1]} and renamed them.\")\n",
    "            move_files(folder, old)\n",
    "            return stop\n",
    "\n",
    "    # define list of all images of tables in newly created subfolders\n",
    "    dirlist = sorted([directory for directory in glob.glob(folder+'*/*') if directory.endswith('.png')])\n",
    "    \n",
    "    # If one of the images is smaller than 50 KB, table extraction probably did not work.\n",
    "    # In that case, stop and continue with next pdf.\n",
    "    \n",
    "    if any(e for e in dirlist if os.path.getsize(e)/1000 < 50):\n",
    "        print(f'problem tables: {[e.split(\"/\")[-2] for e in dirlist if os.path.getsize(e)/1000 < 50]}')\n",
    "        print(f'Table extraction did not work correctly. Continuing with next pdf.')\n",
    "        move_files(folder, old)\n",
    "        return stop\n",
    "        \n",
    "    # Create partial function for cell extraction in which dilation is specified\n",
    "    p_extract_cells = functools.partial(extract_cells.main, dilate)\n",
    "\n",
    "    # Extract individual cell images\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(p_extract_cells, dirlist)\n",
    "    print(f\"extracted cells of {pdf.split('/')[-1]}\")\n",
    "\n",
    "    # define list of directories containing cell images\n",
    "    dirlist = [directory for directory in glob.glob(folder+'*/*/')]\n",
    "\n",
    "    # define list of images of cells within directories\n",
    "    celllists = [glob.glob(cellfolder+'*') for cellfolder in dirlist]\n",
    "\n",
    "    # Specify that there should be no multiple threads.\n",
    "    # This is important because I am already using multiple processors.\n",
    "    # And create partial function to pre-specify thresh and no_noise options.\n",
    "    os.environ['OMP_THREAD_LIMIT'] = '1'\n",
    "    p_ocr_image = functools.partial(ocr_image.main, None, thresh, no_noise)\n",
    "\n",
    "    # perform OCR on each image\n",
    "    for image_list in celllists:\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            executor.map(p_ocr_image, image_list)\n",
    "    print(f\"completed ocr of {pdf.split('/')[-1]}\")\n",
    "\n",
    "    try:\n",
    "        gathered_data = []\n",
    "        # get the names for the individual pages\n",
    "        pages = sorted([filename for directory, filename in\n",
    "                 [os.path.split(x) for x in glob.glob(folder+'*') if not x.endswith(('.pdf', '.png'))]])\n",
    "\n",
    "        # create list of alphabetically ordered lists of ocred files\n",
    "        ocrlists = [sorted(y) for y in\n",
    "                    [glob.glob(f'{folder}/{x}/cells/ocr_data/*.txt') for x in pages]]\n",
    "        zippie = zip(pages, ocrlists)\n",
    "\n",
    "        # for each pair of page and ocred cells, create a csv\n",
    "        for y, x in zippie:\n",
    "            output = ocr_to_csv.main(x)\n",
    "            csv = StringIO(output)\n",
    "            print(f'working on {y}')\n",
    "\n",
    "            # Turning csv into dataframe\n",
    "            # Skipping the first two rows because they have fewer columns than rest\n",
    "            # Also useful for chaining of tables later\n",
    "            df = pd.read_csv(csv,  header = None, skiprows=[0, 1])\n",
    "            gathered_data.append(df)\n",
    "            df = pd.concat(gathered_data)\n",
    "\n",
    "            # give df a name and save it\n",
    "            if from_cell == False:\n",
    "                constituency_name = pages[0][0:5]\n",
    "            else:\n",
    "                constituency_name = pages[0].split('-')[1]\n",
    "            df.to_csv(save_folder+constituency_name+'.csv')\n",
    "\n",
    "        print(f'Saved {constituency_name} to folder.')\n",
    "\n",
    "        # move old files and folders into old_files folder\n",
    "        move_files(folder, old)\n",
    "\n",
    "    # If there is an error, print error message.\n",
    "    # Most likely eror is that header lines (which are not turned into cells properly)\n",
    "    # are three instead of two rows. So we try reading the csvs again, this\n",
    "    # time ignoring the first three instead of just two rows.\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('will try again ignoring one more line.')\n",
    "            # get the names for the individual pages\n",
    "\n",
    "        try:\n",
    "            gathered_data = []\n",
    "            pages = sorted([filename for directory, filename in\n",
    "                     [os.path.split(x) for x in glob.glob(folder+'*') if not x.endswith(('.pdf', '.png'))]])\n",
    "\n",
    "            # create list of alphabetically ordered lists of ocred files\n",
    "\n",
    "            ocrlists = [sorted(y) for y in\n",
    "                        [glob.glob(f'{folder}/{x}/cells/ocr_data/*.txt') for x in pages]]\n",
    "            zippie = zip(pages, ocrlists)\n",
    "\n",
    "            # for each pair of directory and files, create csv file\n",
    "            for y, x in zippie:\n",
    "                output = ocr_to_csv.main(x)\n",
    "                csv = StringIO(output)\n",
    "                print(f'working on {y}')\n",
    "\n",
    "                # Turning csv files into single dataframe\n",
    "                # Skipping the first two rows because they have fewer columns than rest\n",
    "                # Also useful for chaining of tables later\n",
    "                col_names = [str(e) for e in list(range(0,25))]\n",
    "                df = pd.read_csv(csv,  header = None, skiprows=[0, 1], names=col_names)\n",
    "                gathered_data.append(df)\n",
    "                df = pd.concat(gathered_data)\n",
    "\n",
    "                # give df a name and save it\n",
    "                if from_cell == False:\n",
    "                    constituency_name = pages[0][0:5]\n",
    "                else:\n",
    "                    constituency_name = pages[0].split('-')[1]\n",
    "                df.to_csv(save_folder+constituency_name+'.csv')\n",
    "\n",
    "            print(f'Saved {constituency_name} to folder.')\n",
    "\n",
    "            move_files(folder, old)\n",
    "\n",
    "        # If this still does not work, stop the program and try to manually correct mistakes.\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'There is a problem with {pdf.split(\"/\")[-1]}. Continuing with next pdf.')\n",
    "            # move old files and folders into old_files folder\n",
    "            move_files(folder, old)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
