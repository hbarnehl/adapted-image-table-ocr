{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency = '229'\n",
    "folder = '/home/hennes/Internship/constituencies_edit/'\n",
    "df = pd.read_csv(f'{folder}AC{constituency}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make F nan\n",
    "\n",
    "repl_dict = {'F': np.NaN} \n",
    "\n",
    "df = df.replace(repl_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns that have only have a few values in them. They are most likely useless.\n",
    "df.dropna(thresh=len(df) - (len(df)/2), axis=1, inplace=True)\n",
    "# delete rows that have more than 5 missing values\n",
    "df.dropna(thresh = (len(df.columns)/1.4), axis = 0, inplace = True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectifying systematic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform systematic errors\n",
    "repl_dict = {'\\$':'5',\n",
    "             'S':'5',\n",
    "            '\\(4\\)':'(A)',\n",
    "            '4\\)':'(A)',\n",
    "            '(\\(A\\))|(A\\))|(\\(A)|A':'A',\n",
    "            '(\\.0)$':'',\n",
    "            'v':'0',\n",
    "            '_':'',\n",
    "            '\\]':'',\n",
    "            '\\[':'',\n",
    "            '\\|':'',\n",
    "            '\\.':'',\n",
    "            '[\\(\\)]':'',\n",
    "            ' ': '',\n",
    "            '(?!A)\\D':'',\n",
    "            '^\\s*$':np.NaN} \n",
    "\n",
    "df = df.replace(repl_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values with 4 or more digits with NAN\n",
    "\n",
    "repl_dict = {'\\d{4,}': np.NaN} \n",
    "\n",
    "df = df.replace(repl_dict, regex=True)\n",
    "df = df.replace(r'\\s+( +\\.)|#',np.nan,regex=True).replace('',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows that have more than 5 missing values\n",
    "df.dropna(thresh = (len(df.columns)-3), axis = 0, inplace = True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two columns with the highest numbers should be total valid votes and total votes.\n",
    "# Total valid votes is to the left of total votes.\n",
    "\n",
    "# first need to convert columns to int. Should only do that with the non-serial number columns.\n",
    "# This mask selects all columns that do not have 'A' in them.\n",
    "mask = df[[e for e in df.columns]].apply(lambda x:\n",
    "                                         x.astype(str).str.contains(r'A', regex=True)).any(axis='index')\n",
    "\n",
    "# The first is all columns except serial number, second on is only serial number\n",
    "serial = [df.iloc[:,2].name]\n",
    "not_serial = df.loc[:,df.columns != serial[0]].columns.tolist()\n",
    "\n",
    "# then convert all remaining characters to numeric or nan\n",
    "for col in not_serial:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# name column with highest median value 'total votes'    \n",
    "df.rename(columns = {df.median().idxmax(axis=1):'total'}, inplace=True)\n",
    "\n",
    "# exclude it and name the one with second highest median 'total_valid'\n",
    "columns = [col for col in df.columns if not col.startswith('total')]\n",
    "df.rename(columns = {df[columns].median().idxmax(axis=1):'total_valid'}, inplace=True)\n",
    "\n",
    "# sometimes total and total valid will be switched.\n",
    "# Check if column three places to left of total_valid is called total\n",
    "# If so, switch their names\n",
    "if df.columns.tolist()[df.columns.tolist().index('total_valid')-3] == 'total':\n",
    "    df.rename(columns = {'total': 'total_valid', 'total_valid':'total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of columns one and two places to right of 'total valid'\n",
    "sublist = ['total_valid']\n",
    "rejected = df.columns.tolist()[(df.columns.get_indexer(sublist)+1)[0]]\n",
    "nota = df.columns.tolist()[(df.columns.get_indexer(sublist)+2)[0]]\n",
    "first = df.columns.tolist()[0]\n",
    "second = df.columns.tolist()[1]\n",
    "\n",
    "# rename first column 'page_idx' and other columns\n",
    "df.rename(columns={rejected:'rejected',\n",
    "                   nota:'nota',\n",
    "                   first:'page_idx',\n",
    "                   second:'serial_1',\n",
    "                  serial[0]:'serial'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hennes/.local/lib/python3.8/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# delete all rows in which no cell has more than two digits (also accounting for .0)\n",
    "\n",
    "mask = df.apply(lambda x: x.astype(str).str.contains(r'^\\d{,2}(\\.0)?$', regex=True)).all(axis=1)\n",
    "df = df[~mask]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted row 188 to the right.\n",
      "Shifted row 356 to the right.\n",
      "Shifted row 357 to the right.\n",
      "Shifted row 358 to the right.\n"
     ]
    }
   ],
   "source": [
    "# correcting columns wrongly shifted\n",
    "\n",
    "# Identify all rows that have NAN in the column furthest right\n",
    "# and which do not have an 'A' in the serial column. Those should not be moved\n",
    "rowlist = df[(df.iloc[:,-1].isna()) & (~df['serial'].str.contains('A', na=False))].index.tolist()\n",
    "\n",
    "# Calculate how many standard deviations all values of each row are away from the average of the respective columns \n",
    "for row in rowlist:\n",
    "    collist = df.dtypes[df.dtypes == float].index.tolist()\n",
    "    sdlist_old = []\n",
    "    for col in collist:\n",
    "        sdlist_old.append((((df.loc[row, col] - df[col].mean())**2)**0.5) / df[col].std())\n",
    "    \n",
    "# Compute the average standard deviation for each of these rows \n",
    "    rowsd_old = np.nanmedian(sdlist_old)\n",
    "\n",
    "# Shift the values of the row to the right and report the new average standard deviation \n",
    "    df1 = df.copy(deep=True)\n",
    "    df1.loc[row, :] = df1.loc[row, :].shift(1, axis=0)\n",
    "    collist = df1.dtypes[df1.dtypes == float].index.tolist()\n",
    "    sdlist_new = []\n",
    "    for col in collist:\n",
    "        sdlist_new.append((((df1.loc[row, col] - df1[col].mean())**2)**0.5) / df1[col].std())\n",
    "    \n",
    "    rowsd_new = np.nanmedian(sdlist_new)\n",
    "    \n",
    "# Take over the shift if the new SD is smaller than the old SD\n",
    "\n",
    "    if rowsd_old > rowsd_new:\n",
    "        df.loc[row] = df1.loc[row]\n",
    "        print(f'Shifted row {row} to the right.')\n",
    "        \n",
    "        serial = [df.iloc[:,2].name]\n",
    "        not_serial = df.loc[:,df.columns != serial[0]].columns.tolist()\n",
    "\n",
    "        # then convert all remaining characters to numeric or nan\n",
    "        for col in not_serial:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting First Serial Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 359.0, nan\n",
      "after: 359.0, 360.0\n"
     ]
    }
   ],
   "source": [
    "# For errors without a gap (no row is missing)\n",
    "\n",
    "# Idea is: if (n)+1 does not equal (n+1), then see if (n-1)+2 equals (n+1)\n",
    "# This logic is extended for up to 5 numbers ahead of n. In this way, gaps \n",
    "# of up to 4 numbers will be bridged. At the same time, there will be no\n",
    "# interpolation if there is no clean continuation of integers.\n",
    "\n",
    "for n in df.index.tolist()[1:]:\n",
    "    try:\n",
    "        if df.iloc[n,1] != df.iloc[n-1,1]+1:\n",
    "            if df.iloc[n-1,1]+2 == df.iloc[n+1,1]:\n",
    "                df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "            if df.iloc[n-1,1]+3 == df.iloc[n+2,1]:\n",
    "                df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "                df.iloc[n+1,1] = df.iloc[n-1,1]+2\n",
    "            if df.iloc[n-1,1]+4 == df.iloc[n+3,1]:\n",
    "                df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "                df.iloc[n+1,1] = df.iloc[n-1,1]+2\n",
    "                df.iloc[n+2,1] = df.iloc[n-1,1]+3\n",
    "            if df.iloc[n-1,1]+5 == df.iloc[n+4,1]:\n",
    "                df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "                df.iloc[n+1,1] = df.iloc[n-1,1]+2\n",
    "                df.iloc[n+2,1] = df.iloc[n-1,1]+3\n",
    "                df.iloc[n+3,1] = df.iloc[n-1,1]+4\n",
    "            if df.iloc[n-1,1]+6 == df.iloc[n+5,1]:\n",
    "                df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "                df.iloc[n+1,1] = df.iloc[n-1,1]+2\n",
    "                df.iloc[n+2,1] = df.iloc[n-1,1]+3\n",
    "                df.iloc[n+3,1] = df.iloc[n-1,1]+4\n",
    "                df.iloc[n+4,1] = df.iloc[n-1,1]+5\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "# For errors with a gap (occur often between last row of one page and first row of next)\n",
    "# define index of last row of each page\n",
    "last = [x-1 for x in df[df['page_idx']==0].index.tolist()[1:]]\n",
    "\n",
    "# if (n) does not equal (n-1)+1, then make it so\n",
    "for n in last:\n",
    "    try:\n",
    "        if df.iloc[n,1] != df.iloc[n-1,1]+1:\n",
    "            df.iloc[n,1] = df.iloc[n-1,1]+1\n",
    "    except:\n",
    "        None\n",
    "\n",
    "# for errors at beginning of pages\n",
    "\n",
    "for n in df[df['page_idx']==0].index.tolist()[1:]:\n",
    "    if df.iloc[n,1] != df.iloc[n+1,1]-1:\n",
    "        df.iloc[n,1] = df.iloc[n+1,1]-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: nan, 1.0\n",
      "after: 0.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "# for errors at beginning of pages\n",
    "\n",
    "for n in df[df['page_idx']==0].index.tolist()[1:]:\n",
    "    if df.iloc[n,1] != df.iloc[n+1,1]-1:\n",
    "        df.iloc[n,1] = df.iloc[n+1,1]-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out rule to take care of numbers missing digits\n",
    "\n",
    "for n in [e for e in df.index.tolist()[1:] if e not in df[df['page_idx']==0].index.tolist()[1:]]:\n",
    "    try:\n",
    "        if df.iloc[n,1] != df.iloc[n-1,1]+1:\n",
    "            print(f'before: {df.iloc[n-2,1]} first: {df.iloc[n-1,1]} second:{df.iloc[n,1]}')\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': [None, '1A', '', '', '', '', '334', '34', '66', '6', '68', '77A', '7', '79', '88A', '8', '89A'],\n",
    "     'col2': [\"\", '1A', '', '', '', '', '334', '34', '66', '6', '68', '77A', '7', '79', '88A', '8', '89A']}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-516dc9a8a10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         if (int(''.join(c for c in str(df.iloc[n-1,1]) if c.isdigit())) ==\n\u001b[0;32m---> 19\u001b[0;31m             int(''.join(c for c in str(df.iloc[n+1,1]) if c.isdigit()))-1):\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-516dc9a8a10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         print(\"this is n-1:\" , df.iloc[n-1,2], '\\n this is n: ',\n\u001b[0m\u001b[1;32m     23\u001b[0m               df.iloc[n,2], '\\n this is n+1: ', df.iloc[n+1,2])\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# for all rows except last row None\n",
    "for n in df.index.tolist()[:-1]:\n",
    "    # if the next row ends with an A\n",
    "    if str(df.iloc[n+1,1]).endswith(\"A\"):\n",
    "        # then just make n = next row\n",
    "        df.iloc[n,1] = int(''.join(c for c in df.iloc[n+1,1] if c.isdigit()))\n",
    "\n",
    "# for all except first row\n",
    "for n in df.index.tolist()[1:]:\n",
    "    # if the former row ends with an A\n",
    "    if str(df.iloc[n-1,1]).endswith(\"A\"):\n",
    "        # then just make n = former row + 1\n",
    "        df.iloc[n,1] = int(''.join(c for c in df.iloc[n-1,1] if c.isdigit()))+1\n",
    "\n",
    "# for all except first and last row\n",
    "for n in df.index.tolist()[1:-1]:\n",
    "    try:\n",
    "        if (int(''.join(c for c in str(df.iloc[n-1,1]) if c.isdigit())) ==\n",
    "            int(''.join(c for c in str(df.iloc[n+1,1]) if c.isdigit()))-1):\n",
    "            df.iloc[n,1] = ''.join([str(int(''.join(c for c in str(df.iloc[n-1,1]) if c.isdigit()))), 'A'])\n",
    "    except:\n",
    "        print(\"this is n-1:\" , df.iloc[n-1,2], '\\n this is n: ',\n",
    "              df.iloc[n,2], '\\n this is n+1: ', df.iloc[n+1,2])\n",
    "        \n",
    "# in cases where n-1 = n+1 -2 (then n should not have an A and simply be n-1 + 1)\n",
    "for n in df.index.tolist()[1:-1]:\n",
    "    if str(df.iloc[n-1,1]) != '' and str(df.iloc[n+1,1]) != '':\n",
    "        if (int(''.join(c for c in str(df.iloc[n-1,1]) if c.isdigit()))\n",
    "        == int(''.join(c for c in str(df.iloc[n+1,1]) if c.isdigit()))-2):\n",
    "            df.iloc[n,1] = int(''.join(c for c in df.iloc[n-1,1] if c.isdigit()))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna('nan')\n",
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns according to Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rank-party pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency = '025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import excel on candidate names\n",
    "d = pd.read_excel('/home/hennes/Internship/Party_Data_2021.xlsx')\n",
    "# define df excluding NOTA, only current constituency\n",
    "dat = d[(d['PARTY']!= 'NOTA')\n",
    "        & (d['AC NO.']== float(re.findall(r'[1-9][0-9]*',f'AC{constituency}.csv')[0]))][['AC NO.', 'PARTY', 'TOTAL']]\n",
    "# get number of candidates\n",
    "n_candidates = len(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 'BJP', 2.0: 'AITC', 3.0: 'INC', 4.0: 'IND', 5.0: 'BSP', 6.0: 'SUCI'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column with rank of party per constituency\n",
    "dat['rank'] = dat.groupby('AC NO.').rank(ascending=False)\n",
    "# create dict with party value pair\n",
    "rank_party = pd.Series(dat.PARTY.values,index=dat['rank']).to_dict()\n",
    "rank_party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting column-rank pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder+'AC025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with key = column name, value = rank\n",
    "serial = df.columns.get_indexer(['serial'])[0]\n",
    "column_rank = df.iloc[:,serial+1:serial+(n_candidates+1)]\\\n",
    "    .agg(func=np.sum)\\\n",
    "    .rank(ascending=False)\\\n",
    "    .to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column according to rank\n",
    "rename_dict={}\n",
    "for col, rank in column_rank.items():\n",
    "    rename_dict.update({col:rank_party.get(rank)}) \n",
    "df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_idx</th>\n",
       "      <th>serial_1</th>\n",
       "      <th>serial</th>\n",
       "      <th>BJP</th>\n",
       "      <th>AITC</th>\n",
       "      <th>INC</th>\n",
       "      <th>BSP</th>\n",
       "      <th>SUCI</th>\n",
       "      <th>IND</th>\n",
       "      <th>total_valid</th>\n",
       "      <th>rejected</th>\n",
       "      <th>nota</th>\n",
       "      <th>total</th>\n",
       "      <th>12</th>\n",
       "      <th>ac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>203.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>380.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>295.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>304</td>\n",
       "      <td>409.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>305</td>\n",
       "      <td>381.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>305A</td>\n",
       "      <td>304.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>306</td>\n",
       "      <td>247.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>4.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>307</td>\n",
       "      <td>485.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_idx  serial_1 serial    BJP   AITC    INC  BSP  SUCI   IND  \\\n",
       "0         0.0       2.0      2  203.0  273.0    8.0  3.0   2.0   6.0   \n",
       "1         1.0       3.0      3  300.0  513.0   20.0  3.0   4.0  10.0   \n",
       "2         2.0       4.0      4  380.0  159.0   17.0  4.0   2.0   7.0   \n",
       "3         3.0       5.0      5  311.0  258.0   19.0  8.0   6.0   8.0   \n",
       "4         4.0       6.0      6  295.0  192.0   63.0  3.0   3.0  11.0   \n",
       "..        ...       ...    ...    ...    ...    ...  ...   ...   ...   \n",
       "370       0.0     386.0    304  409.0  242.0   85.0  6.0   6.0   2.0   \n",
       "371       1.0     387.0    305  381.0  198.0    5.0  2.0   9.0   5.0   \n",
       "372       2.0     388.0   305A  304.0  174.0   48.0  3.0   2.0   6.0   \n",
       "373       3.0     389.0    306  247.0  189.0   65.0  2.0   2.0   2.0   \n",
       "374       4.0     390.0    307  485.0  260.0  100.0  2.0   3.0   7.0   \n",
       "\n",
       "     total_valid  rejected  nota  total   12  ac  \n",
       "0          495.0       0.0  15.0  510.0  0.0  25  \n",
       "1          450.0       4.0  11.0  461.0  0.0  25  \n",
       "2          569.0       0.0  17.0  586.0  0.0  25  \n",
       "3          610.0       0.0  23.0  633.0  0.0  25  \n",
       "4          567.0       0.0  20.0  587.0  0.0  25  \n",
       "..           ...       ...   ...    ...  ...  ..  \n",
       "370        750.0       0.0  14.0  764.0  0.0  25  \n",
       "371        670.0       0.0  10.0  680.0  0.0  25  \n",
       "372        539.0       0.0   5.0  544.0  0.0  25  \n",
       "373        507.0       0.0   4.0  511.0  0.0  25  \n",
       "374        857.0       0.0  17.0  874.0  0.0  25  \n",
       "\n",
       "[375 rows x 15 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming column according to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import concurrent # for parallel instances\n",
    "import warnings\n",
    "\n",
    "# Defining Selection of Constituencies\n",
    "\n",
    "df = pd.read_excel('/home/hennes/Downloads/Book.xlsx')\n",
    "\n",
    "# get relevant pdf numbers\n",
    "\n",
    "worklist = df[df['Ready for Cleaning and Merging?'] == 'y']['Constituency number'].tolist()\n",
    "\n",
    "# give appropriate filename endings to items\n",
    "\n",
    "for idx, item in enumerate(worklist):\n",
    "    if len(str(item)) == 1:\n",
    "        worklist[idx] = f'AC00{item}.csv'\n",
    "    if len(str(item)) == 2:\n",
    "        worklist[idx] = f'AC0{item}.csv'\n",
    "    if len(str(item)) == 3:\n",
    "        worklist[idx] = f'AC{item}.csv'\n",
    "        \n",
    "worklist = tuple(worklist)\n",
    "\n",
    "# Defining Folders\n",
    "folder = '/home/hennes/Internship/constituencies/'\n",
    "save_folder = '/home/hennes/Internship/constituencies_edit/'\n",
    "old = '/home/hennes/Internship/old_files/'\n",
    "candidates = pd.read_csv('/home/hennes/Internship/Party_Data_2019.csv')\n",
    "PC_AC = set(sorted([folder.split('-')[0]+'-'+ folder.split('-')[1] for folder in next(os.walk(old))[1]]))\n",
    "PC_AC_dict = {e.split('-')[1]: e.split('-')[0] for e in PC_AC}\n",
    "constituencies = sorted([os.path.split(file)[-1] for file in glob.glob(folder+'*') if file.endswith(\".csv\")]) # list with all files\n",
    "constituencies = [file for file in constituencies if file.endswith(worklist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency = 'AC005.csv'\n",
    "df = pd.read_csv('/home/hennes/Internship/constituencies_edit/AC005.csv')\n",
    "candidate_df = pd.read_csv('/home/hennes/Internship/Party_Data_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get appropriate constituency number\n",
    "con_n = PC_AC_dict[constituency.split('.')[0]].split('C')[-1].replace('0', '')\n",
    "\n",
    "# define df excluding NOTA, only current constituency\n",
    "dat = candidate_df[(candidate_df['Party']!= 'NOTA') & (candidate_df['Constituency_No'] == int(con_n))]\\\n",
    "[['Constituency_No', 'Party', 'Votes', 'Constituency_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Votes'] = pd.to_numeric(dat['Votes'], errors='coerce')\n",
    "# create column with rank of party per constituency\n",
    "dat['rank'] = dat.groupby('Constituency_No').rank(ascending=False)\n",
    "# get number of candidates\n",
    "n_candidates = len(dat)\n",
    "# create dict with party value pair\n",
    "rank_party = pd.Series(dat.Party.values,index=dat['rank']).to_dict()\n",
    "\n",
    "# create dictionary with key = column name, value = rank\n",
    "serial = df.columns.get_indexer(['serial'])[0]\n",
    "column_rank = df.iloc[:,serial+1:serial+(n_candidates+1)]\\\n",
    "    .agg(func=np.sum)\\\n",
    "    .rank(ascending=False)\\\n",
    "    .to_dict()\n",
    "\n",
    "df['pc'] = con_n\n",
    "\n",
    "# Renaming column according to rank\n",
    "rename_dict={}\n",
    "for col, rank in column_rank.items():\n",
    "    rename_dict.update({col:rank_party.get(rank)}) \n",
    "df.rename(columns=rename_dict, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
