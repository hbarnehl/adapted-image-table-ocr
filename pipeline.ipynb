{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other necessary packages\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # image transformation\n",
    "import os\n",
    "import re\n",
    "import concurrent # for parallel instances\n",
    "import functools # for creating partial functions\n",
    "import shutil\n",
    "\n",
    "from io import StringIO # to convert string to csv\n",
    "import time # to measure time\n",
    "\n",
    "# to add the path where to search for modules\n",
    "import sys\n",
    "sys.path.append('/home/hennes/Internship/table_scanner')\n",
    "\n",
    "# Importing table_ocr modules \n",
    "from table_ocr import pdf_to_images\n",
    "from table_ocr import extract_tables\n",
    "from table_ocr import extract_cells\n",
    "from table_ocr import ocr_image\n",
    "from table_ocr import ocr_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting folders and pdfs\n",
    "\n",
    "folder = \"/home/hennes/Internship/pdfs\" # should be folder containing pdfs of election\n",
    "save_folder = '/home/hennes/Internship/constituencies/' # folder into which csvs should be saved\n",
    "allpdf = [pdf for pdf in glob.glob(folder+'/*') if pdf.endswith(\".pdf\")] # list with all pdfs from folder\n",
    "\n",
    "# exclude pdfs for which there is already a csv in save folder\n",
    "pdflist = sorted([pdf for pdf in allpdf if pdf.split('/')[-1].split('_')[0].split('.')[0] not in\n",
    "           [file.split('/')[-1].split('.')[0] for file in glob.glob(save_folder+'*')]])\n",
    "\n",
    "# add pdf file names in case they should be manually excluded\n",
    "exclude = ('AC069.pdf', 'AC100.pdf', 'AC005.pdf')\n",
    "pdflist = [x for x in pdflist if not x.endswith(exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete all non-pdf files and folders\n",
    "[shutil.rmtree(folder+'/'+e) for e in next(os.walk(folder))[1]]\n",
    "[os.remove(e) for e in glob.glob(folder+'/*') if not e.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing images\n",
    "def ocr_pipeline(pdf):\n",
    "    \n",
    "    stop = None\n",
    "    \n",
    "    # extract pages from pdf and save as images \n",
    "    pdf_to_images.pdf_to_images(pdf)\n",
    "\n",
    "    # define list of images thus created\n",
    "    imglist = [img for img in glob.glob(folder+'/*') if img.endswith('.png')]\n",
    "    print(f\"created images of {pdf.split('/')[-1]}\")\n",
    "    \n",
    "    # rotate and correct images for skew\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(pdf_to_images.preprocess_img, imglist)\n",
    "    print(f\"preprocessed images of {pdf.split('/')[-1]}\")\n",
    "\n",
    "    # define imglist as list of lists because next function needs list as argument\n",
    "    imglist = [[img] for img in imglist]\n",
    "\n",
    "    # crop images to table and save in new folder\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(extract_tables.main, imglist)\n",
    "    print(f\"extracted tables of {pdf.split('/')[-1]}\")\n",
    "\n",
    "    # define list of all images of tables in newly created subfolders\n",
    "    dirlist = [directory for directory in glob.glob(folder+'/*/*') if directory.endswith('.png')]\n",
    "\n",
    "    # Extract individual cell images\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(extract_cells.main, dirlist)\n",
    "    print(f\"extracted cells of {pdf.split('/')[-1]}\")\n",
    "\n",
    "        \n",
    "    # define list of directories containing cell images\n",
    "    dirlist = [directory for directory in glob.glob(folder+'/*/*/')]\n",
    "    \n",
    "    # define list of images of cells within directories\n",
    "    celllists = [glob.glob(cellfolder+'*') for cellfolder in dirlist]\n",
    "    \n",
    "    # Specify that there should be no multiple threads.\n",
    "    # This is important because I am already using multiple processors.\n",
    "    os.environ['OMP_THREAD_LIMIT'] = '1'\n",
    "    p_ocr_image = functools.partial(ocr_image.main, None)\n",
    "    \n",
    "    # perform OCR on each image\n",
    "    for image_list in celllists:\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            executor.map(p_ocr_image, image_list)\n",
    "    print(f\"completed ocr of {pdf.split('/')[-1]}\")\n",
    "\n",
    "    gathered_data = []\n",
    "\n",
    "    try:\n",
    "        # get the names for the individual pages\n",
    "        pages = sorted([filename for directory, filename in\n",
    "                 [os.path.split(x) for x in glob.glob(folder+'/*') if not x.endswith(('.pdf', '.png'))]])\n",
    "\n",
    "        # create list of alphabetically ordered lists of ocred files\n",
    "        ocrlists = [sorted(y) for y in\n",
    "                    [glob.glob(f'{folder}/{x}/cells/ocr_data/*.txt') for x in pages]]\n",
    "        zippie = zip(pages, ocrlists)\n",
    "        \n",
    "        # for each pair of page and ocred cells, create a csv\n",
    "        for y, x in zippie:\n",
    "            output = ocr_to_csv.main(x)\n",
    "            csv = StringIO(output)\n",
    "            print(f'working on {y}')\n",
    "\n",
    "            # Turning csv into dataframe\n",
    "            # Skipping the first two rows because they have fewer columns than rest\n",
    "            # Also useful for chaining of tables later\n",
    "            df = pd.read_csv(csv,  header = None, skiprows=[0, 1])\n",
    "            gathered_data.append(df)\n",
    "            df = pd.concat(gathered_data)\n",
    "\n",
    "            constituency_name = pages[0][0:5]\n",
    "            df.to_csv(save_folder+constituency_name+'.csv')\n",
    "\n",
    "        print(f'Saved {constituency_name} to folder.')\n",
    "\n",
    "        # delete folders and images created in this iteration of loop\n",
    "        [shutil.rmtree(folder+'/'+e) for e in next(os.walk(folder))[1]]\n",
    "        [os.remove(e) for e in glob.glob(folder+'/*') if not e.endswith('.pdf')]\n",
    "    \n",
    "    # If there is an error, print error message.\n",
    "    # Most likely eror is that header lines (which are not turned into cells properly)\n",
    "    # are three instead of two rows. So we try reading the csvs again, this\n",
    "    # time ignoring the first three instead of just two rows.\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('will try again ignoring one more line.')\n",
    "            # get the names for the individual pages\n",
    "\n",
    "        try:\n",
    "            pages = sorted([filename for directory, filename in\n",
    "                     [os.path.split(x) for x in glob.glob(folder+'/*') if not x.endswith(('.pdf', '.png'))]])\n",
    "\n",
    "            # create list of alphabetically ordered lists of ocred files\n",
    "\n",
    "            ocrlists = [sorted(y) for y in\n",
    "                        [glob.glob(f'{folder}/{x}/cells/ocr_data/*.txt') for x in pages]]\n",
    "            zippie = zip(pages, ocrlists)\n",
    "\n",
    "            for y, x in zippie:\n",
    "                output = ocr_to_csv.main(x)\n",
    "                csv = StringIO(output)\n",
    "                print(f'working on {y}')\n",
    "                # Turning csv into dataframe\n",
    "                # Skipping the first two rows because they have fewer columns than rest\n",
    "                # Also useful for chaining of tables later\n",
    "\n",
    "                df = pd.read_csv(csv,  header = None, skiprows=[0, 1, 2])\n",
    "                gathered_data.append(df)\n",
    "                df = pd.concat(gathered_data)\n",
    "\n",
    "                constituency_name = pages[0][0:5]\n",
    "                df.to_csv(save_folder+constituency_name+'.csv')\n",
    "\n",
    "            print(f'Saved {constituency_name} to folder.')\n",
    "\n",
    "            [shutil.rmtree(folder+'/'+e) for e in next(os.walk(folder))[1]]\n",
    "            [os.remove(e) for e in glob.glob(folder+'/*') if not e.endswith('.pdf')]\n",
    "        \n",
    "        # If this still does not work, stop the program and try to manually correct mistakes.\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            stop = True\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created images of AC006.pdf\n",
      "preprocessed images of AC006.pdf\n",
      "extracted tables of AC006.pdf\n",
      "extracted cells of AC006.pdf\n",
      "completed ocr of AC006.pdf\n",
      "working on AC006-000\n",
      "working on AC006-001\n",
      "working on AC006-002\n",
      "working on AC006-003\n",
      "working on AC006-004\n",
      "working on AC006-005\n",
      "working on AC006-006\n",
      "Error tokenizing data. C error: Expected 15 fields in line 7, saw 16\n",
      "\n",
      "will try again ignoring one more line.\n",
      "working on AC006-000\n",
      "working on AC006-001\n",
      "working on AC006-002\n",
      "working on AC006-003\n",
      "working on AC006-004\n",
      "working on AC006-005\n",
      "working on AC006-006\n",
      "Error tokenizing data. C error: Expected 15 fields in line 7, saw 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in pdflist:\n",
    "    stop = ocr_pipeline(x)\n",
    "    if stop:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
